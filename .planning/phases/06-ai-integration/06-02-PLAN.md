---
phase: 06-ai-integration
plan: 02
type: execute
wave: 2
depends_on: ["06-01"]
files_modified:
  - src-tauri/src/commands/ai.rs
  - src/lib/ai.ts
  - src/stores/aiStore.ts
  - src/stores/index.ts
autonomous: true

must_haves:
  truths:
    - "Claude API request is made with correct headers and body"
    - "SSE stream is parsed and text deltas are extracted"
    - "Each text delta is forwarded to frontend via Channel"
    - "Frontend receives streaming events in real-time"
    - "Errors are handled and reported to frontend"
  artifacts:
    - path: "src-tauri/src/commands/ai.rs"
      provides: "stylize_text streaming command"
      exports: ["stylize_text"]
    - path: "src/lib/ai.ts"
      provides: "Frontend AI service with channel handling"
      exports: ["stylizeText", "AiEvent"]
    - path: "src/stores/aiStore.ts"
      provides: "AI state management"
      exports: ["useAiStore"]
  key_links:
    - from: "src/lib/ai.ts"
      to: "src-tauri/src/commands/ai.rs"
      via: "invoke with Channel"
      pattern: "invoke.*stylize_text.*onEvent.*channel"
    - from: "src/stores/aiStore.ts"
      to: "src/lib/ai.ts"
      via: "calls stylizeText"
      pattern: "stylizeText"
---

<objective>
Implement Claude API streaming via Tauri Channel - the core AI pipeline.

Purpose: This is the heart of the AI integration. It connects the Claude API to the frontend via Tauri's Channel API, enabling real-time streaming of AI-generated text. Without this, there's no AI feature.

Output: Working streaming command that takes selected text + style instructions, streams Claude's response back to the frontend, and exposes state via Zustand store.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/phases/06-ai-integration/06-RESEARCH.md
@.planning/phases/06-ai-integration/06-01-SUMMARY.md

# Existing files to extend
@src-tauri/src/commands/ai.rs
@src/stores/index.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Implement Claude API streaming command in Rust</name>
  <files>
    src-tauri/src/commands/ai.rs
    src-tauri/src/lib.rs
  </files>
  <action>
1. Extend src-tauri/src/commands/ai.rs with the streaming command:

Add imports at top:
```rust
use reqwest::Client;
use eventsource_stream::Eventsource;
use futures::StreamExt;
use tauri::ipc::Channel;
use serde::{Deserialize, Serialize};
```

Add event enum for Channel:
```rust
#[derive(Clone, Serialize)]
#[serde(rename_all = "camelCase", tag = "event", content = "data")]
pub enum AiEvent {
    Started,
    TextDelta { text: String },
    Finished { full_text: String },
    Error { message: String },
}
```

Add Claude SSE parsing structs:
```rust
#[derive(Deserialize)]
struct ClaudeStreamEvent {
    #[serde(rename = "type")]
    event_type: String,
    #[serde(default)]
    delta: Option<TextDelta>,
}

#[derive(Deserialize)]
struct TextDelta {
    #[serde(rename = "type")]
    delta_type: String,
    #[serde(default)]
    text: Option<String>,
}
```

Add the streaming command:
```rust
const CLAUDE_API_URL: &str = "https://api.anthropic.com/v1/messages";
const API_VERSION: &str = "2023-06-01";

#[tauri::command]
pub async fn stylize_text(
    app: tauri::AppHandle,
    text: String,
    style_instructions: String,
    document_context: Option<String>,
    on_event: Channel<AiEvent>,
) -> Result<(), String> {
    // Get API key from keychain
    let api_key = app
        .keyring()
        .map_err(|e| format!("Keyring error: {}", e))?
        .get_password(SERVICE, KEY_NAME)
        .map_err(|e| match e {
            keyring::Error::NoEntry => "API key not configured. Please add your Claude API key in settings.".to_string(),
            _ => format!("Failed to retrieve API key: {}", e),
        })?;

    if api_key.is_empty() {
        return Err("API key not configured. Please add your Claude API key in settings.".to_string());
    }

    on_event.send(AiEvent::Started).map_err(|e| e.to_string())?;

    // Build prompt with optional document context
    let prompt = if let Some(ctx) = document_context {
        format!(
            "You are a writing assistant. Rewrite the following text according to these style instructions.\n\n\
            Document context (for tone/style reference, do not include in output):\n{}\n\n\
            Style instructions: {}\n\n\
            Text to rewrite:\n{}\n\n\
            Return ONLY the rewritten text, no explanations or preamble.",
            ctx, style_instructions, text
        )
    } else {
        format!(
            "You are a writing assistant. Rewrite the following text according to these style instructions.\n\n\
            Style instructions: {}\n\n\
            Text to rewrite:\n{}\n\n\
            Return ONLY the rewritten text, no explanations or preamble.",
            style_instructions, text
        )
    };

    let client = Client::new();
    let response = client
        .post(CLAUDE_API_URL)
        .header("x-api-key", &api_key)
        .header("anthropic-version", API_VERSION)
        .header("content-type", "application/json")
        .json(&serde_json::json!({
            "model": "claude-sonnet-4-5-20250514",
            "max_tokens": 4096,
            "stream": true,
            "messages": [{
                "role": "user",
                "content": prompt
            }]
        }))
        .send()
        .await
        .map_err(|e| format!("HTTP request failed: {}", e))?;

    if !response.status().is_success() {
        let status = response.status();
        let error_text = response.text().await.unwrap_or_default();
        let error_msg = format!("Claude API error ({}): {}", status, error_text);
        on_event.send(AiEvent::Error { message: error_msg.clone() }).ok();
        return Err(error_msg);
    }

    let mut full_text = String::new();
    let mut stream = response.bytes_stream().eventsource();

    while let Some(event_result) = stream.next().await {
        match event_result {
            Ok(ev) => {
                // Skip non-data events
                if ev.event == "content_block_delta" {
                    if let Ok(data) = serde_json::from_str::<ClaudeStreamEvent>(&ev.data) {
                        if let Some(delta) = data.delta {
                            if delta.delta_type == "text_delta" {
                                if let Some(text_chunk) = delta.text {
                                    full_text.push_str(&text_chunk);
                                    on_event.send(AiEvent::TextDelta {
                                        text: text_chunk
                                    }).ok();
                                }
                            }
                        }
                    }
                } else if ev.event == "message_stop" {
                    break;
                } else if ev.event == "error" {
                    let error_msg = format!("Stream error: {}", ev.data);
                    on_event.send(AiEvent::Error { message: error_msg.clone() }).ok();
                    return Err(error_msg);
                }
                // Ignore other events (ping, message_start, content_block_start, etc.)
            }
            Err(e) => {
                let error_msg = format!("Stream read error: {}", e);
                on_event.send(AiEvent::Error { message: error_msg.clone() }).ok();
                return Err(error_msg);
            }
        }
    }

    on_event.send(AiEvent::Finished { full_text }).map_err(|e| e.to_string())?;
    Ok(())
}
```

2. Update src-tauri/src/lib.rs invoke_handler to include stylize_text:
   Change the generate_handler! to include `commands::stylize_text`

Note: The keyring() method is from KeyringExt trait - make sure `use tauri_plugin_keyring::KeyringExt;` is in ai.rs
  </action>
  <verify>
Run `cd /Users/jacquesdubnov/Coding/serq/src-tauri && cargo check` - should compile without errors
  </verify>
  <done>
Rust backend has stylize_text command that streams Claude API responses via Tauri Channel
  </done>
</task>

<task type="auto">
  <name>Task 2: Create frontend AI service with Channel handling</name>
  <files>
    src/lib/ai.ts
  </files>
  <action>
Create src/lib/ai.ts:

```typescript
import { invoke, Channel } from '@tauri-apps/api/core';

/**
 * AI event types from Rust backend
 * Must match AiEvent enum in ai.rs
 */
export type AiEvent =
  | { event: 'started' }
  | { event: 'textDelta'; data: { text: string } }
  | { event: 'finished'; data: { fullText: string } }
  | { event: 'error'; data: { message: string } };

export interface StylizeOptions {
  /** The text to stylize */
  text: string;
  /** Style instructions (e.g., "Make it more formal", "Simplify", "Add humor") */
  styleInstructions: string;
  /** Optional surrounding document context for tone matching */
  documentContext?: string;
  /** Called for each text chunk received */
  onDelta?: (text: string) => void;
  /** Called when streaming completes with full result */
  onComplete?: (fullText: string) => void;
  /** Called on error */
  onError?: (message: string) => void;
  /** Called when streaming starts */
  onStart?: () => void;
}

/**
 * Stylize text using Claude API via Tauri backend
 *
 * Example:
 * ```ts
 * await stylizeText({
 *   text: "The meeting went well",
 *   styleInstructions: "Make it more formal and professional",
 *   onDelta: (chunk) => setPreview(prev => prev + chunk),
 *   onComplete: (result) => setFinalResult(result),
 *   onError: (msg) => showError(msg)
 * });
 * ```
 */
export async function stylizeText(options: StylizeOptions): Promise<string> {
  const {
    text,
    styleInstructions,
    documentContext,
    onDelta,
    onComplete,
    onError,
    onStart
  } = options;

  return new Promise((resolve, reject) => {
    const channel = new Channel<AiEvent>();
    let fullText = '';

    channel.onmessage = (message) => {
      switch (message.event) {
        case 'started':
          onStart?.();
          break;
        case 'textDelta':
          fullText += message.data.text;
          onDelta?.(message.data.text);
          break;
        case 'finished':
          onComplete?.(message.data.fullText);
          resolve(message.data.fullText);
          break;
        case 'error':
          onError?.(message.data.message);
          reject(new Error(message.data.message));
          break;
      }
    };

    invoke('stylize_text', {
      text,
      styleInstructions,
      documentContext: documentContext || null,
      onEvent: channel,
    }).catch((err) => {
      // Handle invoke-level errors (command not found, etc.)
      const message = err instanceof Error ? err.message : String(err);
      onError?.(message);
      reject(err);
    });
  });
}

/**
 * Preset style instructions for common operations
 */
export const STYLE_PRESETS = {
  formal: 'Make the text more formal and professional. Use precise language and avoid contractions.',
  casual: 'Make the text more casual and conversational. Use natural language and friendly tone.',
  concise: 'Make the text more concise. Remove unnecessary words while preserving meaning.',
  expand: 'Expand the text with more detail and explanation. Add context where helpful.',
  simplify: 'Simplify the text. Use shorter sentences and simpler words.',
  academic: 'Rewrite in academic style. Use formal language and proper citations format.',
  creative: 'Make the text more creative and engaging. Add vivid descriptions and varied sentence structure.',
  persuasive: 'Make the text more persuasive. Add compelling arguments and calls to action.',
} as const;

export type StylePreset = keyof typeof STYLE_PRESETS;
```

This service:
- Defines TypeScript types matching Rust AiEvent enum
- Provides stylizeText function with callback-based streaming
- Returns a Promise for async/await usage
- Includes preset style instructions for quick access
  </action>
  <verify>
- File exists at src/lib/ai.ts
- TypeScript compiles: `npm run build` passes
- Exports stylizeText function and STYLE_PRESETS
  </verify>
  <done>
Frontend has AI service that invokes Rust command and handles streaming via Channel callbacks
  </done>
</task>

<task type="auto">
  <name>Task 3: Create AI state management store</name>
  <files>
    src/stores/aiStore.ts
    src/stores/index.ts
  </files>
  <action>
1. Create src/stores/aiStore.ts:

```typescript
import { create } from 'zustand';
import { stylizeText, StylePreset, STYLE_PRESETS } from '../lib/ai';

interface AiState {
  // Streaming state
  isLoading: boolean;
  streamingText: string;
  error: string | null;

  // Selection state (what user selected for stylization)
  originalText: string;
  originalRange: { from: number; to: number } | null;

  // Result state
  resultText: string | null;
  showPreview: boolean;

  // Actions
  startStylization: (
    text: string,
    range: { from: number; to: number },
    styleInstructions: string,
    documentContext?: string
  ) => Promise<void>;
  acceptResult: () => void;
  rejectResult: () => void;
  reset: () => void;
}

const initialState = {
  isLoading: false,
  streamingText: '',
  error: null,
  originalText: '',
  originalRange: null,
  resultText: null,
  showPreview: false,
};

export const useAiStore = create<AiState>((set, get) => ({
  ...initialState,

  startStylization: async (text, range, styleInstructions, documentContext) => {
    set({
      isLoading: true,
      streamingText: '',
      error: null,
      originalText: text,
      originalRange: range,
      resultText: null,
      showPreview: true,
    });

    try {
      const result = await stylizeText({
        text,
        styleInstructions,
        documentContext,
        onStart: () => {
          // Already set loading in the initial set call
        },
        onDelta: (chunk) => {
          set((state) => ({
            streamingText: state.streamingText + chunk
          }));
        },
        onComplete: (fullText) => {
          set({
            resultText: fullText,
            isLoading: false
          });
        },
        onError: (message) => {
          set({
            error: message,
            isLoading: false,
            showPreview: false,
          });
        },
      });
      return result;
    } catch (err) {
      // Error already handled by onError callback
      throw err;
    }
  },

  acceptResult: () => {
    // This will be called by editor integration to apply the change
    // The actual editor manipulation happens in the component that calls this
    // We just update our state
    set({
      ...initialState,
    });
  },

  rejectResult: () => {
    set({
      ...initialState,
    });
  },

  reset: () => {
    set({
      ...initialState,
    });
  },
}));

// Export preset helpers
export { STYLE_PRESETS };
export type { StylePreset };
```

2. Update src/stores/index.ts to export aiStore:
   Add: `export { useAiStore, STYLE_PRESETS } from './aiStore';`
   Add type export: `export type { StylePreset } from './aiStore';`
  </action>
  <verify>
- File exists at src/stores/aiStore.ts
- TypeScript compiles: `npm run build` passes
- Store is exported from src/stores/index.ts
  </verify>
  <done>
AI state management store exists with startStylization, acceptResult, rejectResult actions and streaming state
  </done>
</task>

</tasks>

<verification>
1. Rust compiles: `cd src-tauri && cargo check` passes
2. Frontend builds: `npm run build` passes
3. Integration test (requires API key):
   - Configure API key in settings (from Plan 01)
   - In dev console:
     ```js
     import { stylizeText } from './lib/ai';
     stylizeText({
       text: 'hello world',
       styleInstructions: 'make it formal',
       onDelta: (t) => console.log('delta:', t),
       onComplete: (t) => console.log('done:', t)
     });
     ```
   - Should see streaming text chunks in console
</verification>

<success_criteria>
- Rust streaming command compiles and is registered
- Frontend can invoke streaming command via Channel
- AI store manages loading/streaming/result state
- Text deltas arrive in real-time during streaming
- Errors are properly caught and surfaced to UI state
</success_criteria>

<output>
After completion, create `.planning/phases/06-ai-integration/06-02-SUMMARY.md`
</output>
